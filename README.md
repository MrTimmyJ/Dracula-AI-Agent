# Dracula AI Agent
#### VampChat: Talk with Dracula

An interactive chatbot trained on Bram Stokerâ€™s Dracula.
Built with a custom GPT-style model in PyTorch, deployed via FastAPI + Nginx, and featuring a real-time chat UI.

Author: Timothy Johnson <br>
Date: August 2025

### Live Demo

[Dracula AI Agent - VampChat](http://143.198.51.64/dracula-ai/)

### Hugging Face Model

[Dracula AI Model](https://huggingface.co/MrTimmyJ/Dracula/tree/main)

## Overview

&nbsp;&nbsp;&nbsp;&nbsp; Dracula AI Agent is an interactive, full-stack AI chatbot trained on Bram Stokerâ€™s Dracula. Originally built as a Hugging Face model, it has since been expanded into a production-ready FastAPI web service, hosted on an Ubuntu server with Nginx.

&nbsp;&nbsp;&nbsp;&nbsp; The system combines a PyTorch-based GPT-style model (trained from scratch with tiktoken tokenization) and a frontend chat UI (â€œVampChatâ€) that allows users to converse with Dracula in real time. This project demonstrates expertise in machine learning, backend deployment, and AI-driven web applications.

ğŸ§© Features

    ğŸ“š Custom GPT Model: Transformer-style architecture trained on full Dracula text.

    ğŸ”¡ tiktoken Tokenization: GPT-2 compatible encoding for efficient batching.

    ğŸ” Training Pipeline: PyTorch training loop with checkpointing and evaluation.

    ğŸ“ˆ Diagnostics: Real-time loss visualization with Matplotlib.

    ğŸ§› Interactive Chat UI: Web frontend where users â€œtalk with Dracula.â€

    ğŸŒ Web Deployment: FastAPI backend served directly, with NGINX handling static frontend files.  

    âš¡ Chat Integration: Frontend sends POST requests to FastAPI to generate Draculaâ€™s responses in real time.

ğŸ”„ User Workflow

    Place the cleaned Dracula text into your data directory

    Run training with Python gpt_train.py

    Monitor training loss and visual plots

    Generate text samples using a provided prompt

    Save and load model checkpoints for further experimentation

ğŸ“ Code Structure

.<br>
dracula-ai/<br>
â”œâ”€â”€ static/<br> 
â”‚   â”œâ”€â”€ index.html &nbsp;&nbsp;&nbsp;---&nbsp;&nbsp;&nbsp; Main web UI page<br>
â”‚   â””â”€â”€ favicon.ico &nbsp;&nbsp;&nbsp;---&nbsp;&nbsp;&nbsp; Site icon<br>
â”œâ”€â”€ app.py &nbsp;&nbsp;&nbsp;---&nbsp;&nbsp;&nbsp; FastAPI main app entrypoint<br>
â”œâ”€â”€ model_code.py &nbsp;&nbsp;&nbsp;---&nbsp;&nbsp;&nbsp; AI model code (loading, text generation functions, etc)<br>
â”œâ”€â”€ model.pth &nbsp;&nbsp;&nbsp;---&nbsp;&nbsp;&nbsp; PyTorch model checkpoint file (weights)<br>

âš™ï¸ How It Works

ğŸ§  Model Architecture

    GPT-style transformer with token and positional embeddings
    
    Trained with cross-entropy loss using AdamW
    
    Inference supports temperature/top-k sampling for varied outputs

ğŸ“Š Tokenization & Data Pipeline

    tiktoken (GPT-2) encoding for efficient tokenization
    
    Text chunked into fixed-length context windows with stride
    
    PyTorch DataLoader batches/shuffles train/validation splits

ğŸ§ª Training & Evaluation

    Multi-epoch training with periodic validation passes
    
    Loss tracking and visualization for diagnostics
    
    Checkpoint save/load via torch.save / torch.load

ğŸ–¥ï¸ Backend API

    FastAPI endpoints (e.g., /generate) serve model inference
    
    JSON request/response schema for prompts and outputs
    
    CORS enabled for browser clients behind Nginx

ğŸ’¬ Frontend

    HTML/CSS/JavaScript chat UI (â€œVampChatâ€)
    
    Sends user prompts to the API; renders model replies (optionally streamed)
    
    Simple session controls (new chat/clear history)

ğŸŒ Hosting & Deployment
    
    Deployed on Ubuntu with Nginx reverse proxying to the FastAPI app
    
    Nginx serves static frontend and proxies API requests
    
    Basic logging/monitoring for reliable production use

ğŸ–¼ï¸ Screenshots / Visuals

<img width="1024" height="768" alt="vampchat_banner" src="https://github.com/user-attachments/assets/73fd4f8f-6e22-4fd6-8626-e3e49db6d27a" />

ğŸ§° Technologies Used

    ğŸ Python	Core programming language
    
    ğŸ”¦ PyTorch	ML framework
    
    ğŸ”¡ tiktoken	GPT-2 tokenization
    
    ğŸ§  Custom GPT Transformer	model implementation

    ğŸ§ª AdamW	Optimizer for stable convergence
    
    ğŸ“ˆ Matplotlib	training visualization
    
    ğŸš€ FastAPI	backend API for serving model
    
    ğŸŒ JavaScript (ES6), HTML, CSS	chat frontend

    ğŸ§ Ubuntu Server + Nginx	production deployment

    ğŸ’¾ torch.save / torch.load	checkpointing

ğŸš€ Getting Started

    To clone and run this project locally:

      git clone https://github.com/MrTimmyJ/Dracula-AI-Agent.git
      cd Dracula-AI-Agent
      pip install pytorch

      Open static/index.html

      âš ï¸ Requires Python 3.8+ and PyTorch installed (https://pytorch.org/get-started)

ğŸªª License

This project is licensed under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).
